{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFtX6eqX6bMo"
      },
      "source": [
        "# ARTIFICIAL NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAutZbN36hvj"
      },
      "source": [
        "## IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Vb4gyUrrzcJ4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yktl-U8-6qgq"
      },
      "source": [
        "# DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfrOKtMU6xVw"
      },
      "source": [
        "## IMPORTING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "pmwhZzXW0Fa4",
        "outputId": "12c115e4-ee2a-4fba-caab-aad16d7976f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id   Date  number of bedrooms  number of bathrooms  living area  \\\n",
              "0  6762810145  42491                   5                 2.50         3650   \n",
              "1  6762810635  42491                   4                 2.50         2920   \n",
              "2  6762810998  42491                   5                 2.75         2910   \n",
              "3  6762812605  42491                   4                 2.50         3310   \n",
              "4  6762812919  42491                   3                 2.00         2710   \n",
              "\n",
              "   lot area  number of floors  waterfront present  number of views  \\\n",
              "0      9050               2.0                   0                4   \n",
              "1      4000               1.5                   0                0   \n",
              "2      9480               1.5                   0                0   \n",
              "3     42998               2.0                   0                0   \n",
              "4      4500               1.5                   0                0   \n",
              "\n",
              "   condition of the house  ...  Built Year  Renovation Year  Postal Code  \\\n",
              "0                       5  ...        1921                0       122003   \n",
              "1                       5  ...        1909                0       122004   \n",
              "2                       3  ...        1939                0       122004   \n",
              "3                       3  ...        2001                0       122005   \n",
              "4                       4  ...        1929                0       122006   \n",
              "\n",
              "   Lattitude  Longitude  living_area_renov  lot_area_renov  \\\n",
              "0    52.8645   -114.557               2880            5400   \n",
              "1    52.8878   -114.470               2470            4000   \n",
              "2    52.8852   -114.468               2940            6600   \n",
              "3    52.9532   -114.321               3350           42847   \n",
              "4    52.9047   -114.485               2060            4500   \n",
              "\n",
              "   Number of schools nearby  Distance from the airport    Price  \n",
              "0                         2                         58  2380000  \n",
              "1                         2                         51  1400000  \n",
              "2                         1                         53  1200000  \n",
              "3                         3                         76   838000  \n",
              "4                         1                         51   805000  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd92ba63-473b-4824-9449-a1a130e76546\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Date</th>\n",
              "      <th>number of bedrooms</th>\n",
              "      <th>number of bathrooms</th>\n",
              "      <th>living area</th>\n",
              "      <th>lot area</th>\n",
              "      <th>number of floors</th>\n",
              "      <th>waterfront present</th>\n",
              "      <th>number of views</th>\n",
              "      <th>condition of the house</th>\n",
              "      <th>...</th>\n",
              "      <th>Built Year</th>\n",
              "      <th>Renovation Year</th>\n",
              "      <th>Postal Code</th>\n",
              "      <th>Lattitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>living_area_renov</th>\n",
              "      <th>lot_area_renov</th>\n",
              "      <th>Number of schools nearby</th>\n",
              "      <th>Distance from the airport</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6762810145</td>\n",
              "      <td>42491</td>\n",
              "      <td>5</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3650</td>\n",
              "      <td>9050</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>1921</td>\n",
              "      <td>0</td>\n",
              "      <td>122003</td>\n",
              "      <td>52.8645</td>\n",
              "      <td>-114.557</td>\n",
              "      <td>2880</td>\n",
              "      <td>5400</td>\n",
              "      <td>2</td>\n",
              "      <td>58</td>\n",
              "      <td>2380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6762810635</td>\n",
              "      <td>42491</td>\n",
              "      <td>4</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2920</td>\n",
              "      <td>4000</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>1909</td>\n",
              "      <td>0</td>\n",
              "      <td>122004</td>\n",
              "      <td>52.8878</td>\n",
              "      <td>-114.470</td>\n",
              "      <td>2470</td>\n",
              "      <td>4000</td>\n",
              "      <td>2</td>\n",
              "      <td>51</td>\n",
              "      <td>1400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6762810998</td>\n",
              "      <td>42491</td>\n",
              "      <td>5</td>\n",
              "      <td>2.75</td>\n",
              "      <td>2910</td>\n",
              "      <td>9480</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>1939</td>\n",
              "      <td>0</td>\n",
              "      <td>122004</td>\n",
              "      <td>52.8852</td>\n",
              "      <td>-114.468</td>\n",
              "      <td>2940</td>\n",
              "      <td>6600</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>1200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6762812605</td>\n",
              "      <td>42491</td>\n",
              "      <td>4</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3310</td>\n",
              "      <td>42998</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>2001</td>\n",
              "      <td>0</td>\n",
              "      <td>122005</td>\n",
              "      <td>52.9532</td>\n",
              "      <td>-114.321</td>\n",
              "      <td>3350</td>\n",
              "      <td>42847</td>\n",
              "      <td>3</td>\n",
              "      <td>76</td>\n",
              "      <td>838000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6762812919</td>\n",
              "      <td>42491</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2710</td>\n",
              "      <td>4500</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>1929</td>\n",
              "      <td>0</td>\n",
              "      <td>122006</td>\n",
              "      <td>52.9047</td>\n",
              "      <td>-114.485</td>\n",
              "      <td>2060</td>\n",
              "      <td>4500</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>805000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd92ba63-473b-4824-9449-a1a130e76546')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd92ba63-473b-4824-9449-a1a130e76546 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd92ba63-473b-4824-9449-a1a130e76546');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df=pd.read_csv(\"/content/House Price India.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxfbxtWG5kUl",
        "outputId": "02df24c8-4154-4a1a-cc6a-1b6638d0928c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14620 entries, 0 to 14619\n",
            "Data columns (total 23 columns):\n",
            " #   Column                                 Non-Null Count  Dtype  \n",
            "---  ------                                 --------------  -----  \n",
            " 0   id                                     14620 non-null  int64  \n",
            " 1   Date                                   14620 non-null  int64  \n",
            " 2   number of bedrooms                     14620 non-null  int64  \n",
            " 3   number of bathrooms                    14620 non-null  float64\n",
            " 4   living area                            14620 non-null  int64  \n",
            " 5   lot area                               14620 non-null  int64  \n",
            " 6   number of floors                       14620 non-null  float64\n",
            " 7   waterfront present                     14620 non-null  int64  \n",
            " 8   number of views                        14620 non-null  int64  \n",
            " 9   condition of the house                 14620 non-null  int64  \n",
            " 10  grade of the house                     14620 non-null  int64  \n",
            " 11  Area of the house(excluding basement)  14620 non-null  int64  \n",
            " 12  Area of the basement                   14620 non-null  int64  \n",
            " 13  Built Year                             14620 non-null  int64  \n",
            " 14  Renovation Year                        14620 non-null  int64  \n",
            " 15  Postal Code                            14620 non-null  int64  \n",
            " 16  Lattitude                              14620 non-null  float64\n",
            " 17  Longitude                              14620 non-null  float64\n",
            " 18  living_area_renov                      14620 non-null  int64  \n",
            " 19  lot_area_renov                         14620 non-null  int64  \n",
            " 20  Number of schools nearby               14620 non-null  int64  \n",
            " 21  Distance from the airport              14620 non-null  int64  \n",
            " 22  Price                                  14620 non-null  int64  \n",
            "dtypes: float64(4), int64(19)\n",
            "memory usage: 2.6 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "hdMit0lU5n2p",
        "outputId": "656d0ff5-d048-4334-dad9-cb2679ac6f76"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id          Date  number of bedrooms  number of bathrooms  \\\n",
              "count  1.462000e+04  14620.000000        14620.000000         14620.000000   \n",
              "mean   6.762821e+09  42604.538646            3.379343             2.129583   \n",
              "std    6.237575e+03     67.347991            0.938719             0.769934   \n",
              "min    6.762810e+09  42491.000000            1.000000             0.500000   \n",
              "25%    6.762815e+09  42546.000000            3.000000             1.750000   \n",
              "50%    6.762821e+09  42600.000000            3.000000             2.250000   \n",
              "75%    6.762826e+09  42662.000000            4.000000             2.500000   \n",
              "max    6.762832e+09  42734.000000           33.000000             8.000000   \n",
              "\n",
              "        living area      lot area  number of floors  waterfront present  \\\n",
              "count  14620.000000  1.462000e+04      14620.000000        14620.000000   \n",
              "mean    2098.262996  1.509328e+04          1.502360            0.007661   \n",
              "std      928.275721  3.791962e+04          0.540239            0.087193   \n",
              "min      370.000000  5.200000e+02          1.000000            0.000000   \n",
              "25%     1440.000000  5.010750e+03          1.000000            0.000000   \n",
              "50%     1930.000000  7.620000e+03          1.500000            0.000000   \n",
              "75%     2570.000000  1.080000e+04          2.000000            0.000000   \n",
              "max    13540.000000  1.074218e+06          3.500000            1.000000   \n",
              "\n",
              "       number of views  condition of the house  ...    Built Year  \\\n",
              "count     14620.000000            14620.000000  ...  14620.000000   \n",
              "mean          0.233105                3.430506  ...   1970.926402   \n",
              "std           0.766259                0.664151  ...     29.493625   \n",
              "min           0.000000                1.000000  ...   1900.000000   \n",
              "25%           0.000000                3.000000  ...   1951.000000   \n",
              "50%           0.000000                3.000000  ...   1975.000000   \n",
              "75%           0.000000                4.000000  ...   1997.000000   \n",
              "max           4.000000                5.000000  ...   2015.000000   \n",
              "\n",
              "       Renovation Year    Postal Code     Lattitude     Longitude  \\\n",
              "count     14620.000000   14620.000000  14620.000000  14620.000000   \n",
              "mean         90.924008  122033.062244     52.792848   -114.404007   \n",
              "std         416.216661      19.082418      0.137522      0.141326   \n",
              "min           0.000000  122003.000000     52.385900   -114.709000   \n",
              "25%           0.000000  122017.000000     52.707600   -114.519000   \n",
              "50%           0.000000  122032.000000     52.806400   -114.421000   \n",
              "75%           0.000000  122048.000000     52.908900   -114.315000   \n",
              "max        2015.000000  122072.000000     53.007600   -113.505000   \n",
              "\n",
              "       living_area_renov  lot_area_renov  Number of schools nearby  \\\n",
              "count       14620.000000    14620.000000              14620.000000   \n",
              "mean         1996.702257    12753.500068                  2.012244   \n",
              "std           691.093366    26058.414467                  0.817284   \n",
              "min           460.000000      651.000000                  1.000000   \n",
              "25%          1490.000000     5097.750000                  1.000000   \n",
              "50%          1850.000000     7620.000000                  2.000000   \n",
              "75%          2380.000000    10125.000000                  3.000000   \n",
              "max          6110.000000   560617.000000                  3.000000   \n",
              "\n",
              "       Distance from the airport         Price  \n",
              "count               14620.000000  1.462000e+04  \n",
              "mean                   64.950958  5.389322e+05  \n",
              "std                     8.936008  3.675324e+05  \n",
              "min                    50.000000  7.800000e+04  \n",
              "25%                    57.000000  3.200000e+05  \n",
              "50%                    65.000000  4.500000e+05  \n",
              "75%                    73.000000  6.450000e+05  \n",
              "max                    80.000000  7.700000e+06  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46559672-ae72-424d-8fa7-0f7e42a75fb5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Date</th>\n",
              "      <th>number of bedrooms</th>\n",
              "      <th>number of bathrooms</th>\n",
              "      <th>living area</th>\n",
              "      <th>lot area</th>\n",
              "      <th>number of floors</th>\n",
              "      <th>waterfront present</th>\n",
              "      <th>number of views</th>\n",
              "      <th>condition of the house</th>\n",
              "      <th>...</th>\n",
              "      <th>Built Year</th>\n",
              "      <th>Renovation Year</th>\n",
              "      <th>Postal Code</th>\n",
              "      <th>Lattitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>living_area_renov</th>\n",
              "      <th>lot_area_renov</th>\n",
              "      <th>Number of schools nearby</th>\n",
              "      <th>Distance from the airport</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.462000e+04</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>1.462000e+04</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>14620.000000</td>\n",
              "      <td>1.462000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.762821e+09</td>\n",
              "      <td>42604.538646</td>\n",
              "      <td>3.379343</td>\n",
              "      <td>2.129583</td>\n",
              "      <td>2098.262996</td>\n",
              "      <td>1.509328e+04</td>\n",
              "      <td>1.502360</td>\n",
              "      <td>0.007661</td>\n",
              "      <td>0.233105</td>\n",
              "      <td>3.430506</td>\n",
              "      <td>...</td>\n",
              "      <td>1970.926402</td>\n",
              "      <td>90.924008</td>\n",
              "      <td>122033.062244</td>\n",
              "      <td>52.792848</td>\n",
              "      <td>-114.404007</td>\n",
              "      <td>1996.702257</td>\n",
              "      <td>12753.500068</td>\n",
              "      <td>2.012244</td>\n",
              "      <td>64.950958</td>\n",
              "      <td>5.389322e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.237575e+03</td>\n",
              "      <td>67.347991</td>\n",
              "      <td>0.938719</td>\n",
              "      <td>0.769934</td>\n",
              "      <td>928.275721</td>\n",
              "      <td>3.791962e+04</td>\n",
              "      <td>0.540239</td>\n",
              "      <td>0.087193</td>\n",
              "      <td>0.766259</td>\n",
              "      <td>0.664151</td>\n",
              "      <td>...</td>\n",
              "      <td>29.493625</td>\n",
              "      <td>416.216661</td>\n",
              "      <td>19.082418</td>\n",
              "      <td>0.137522</td>\n",
              "      <td>0.141326</td>\n",
              "      <td>691.093366</td>\n",
              "      <td>26058.414467</td>\n",
              "      <td>0.817284</td>\n",
              "      <td>8.936008</td>\n",
              "      <td>3.675324e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.762810e+09</td>\n",
              "      <td>42491.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>370.000000</td>\n",
              "      <td>5.200000e+02</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1900.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>122003.000000</td>\n",
              "      <td>52.385900</td>\n",
              "      <td>-114.709000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>651.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>7.800000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.762815e+09</td>\n",
              "      <td>42546.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>5.010750e+03</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1951.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>122017.000000</td>\n",
              "      <td>52.707600</td>\n",
              "      <td>-114.519000</td>\n",
              "      <td>1490.000000</td>\n",
              "      <td>5097.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>3.200000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.762821e+09</td>\n",
              "      <td>42600.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>1930.000000</td>\n",
              "      <td>7.620000e+03</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1975.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>122032.000000</td>\n",
              "      <td>52.806400</td>\n",
              "      <td>-114.421000</td>\n",
              "      <td>1850.000000</td>\n",
              "      <td>7620.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>4.500000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.762826e+09</td>\n",
              "      <td>42662.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2570.000000</td>\n",
              "      <td>1.080000e+04</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1997.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>122048.000000</td>\n",
              "      <td>52.908900</td>\n",
              "      <td>-114.315000</td>\n",
              "      <td>2380.000000</td>\n",
              "      <td>10125.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>6.450000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6.762832e+09</td>\n",
              "      <td>42734.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>13540.000000</td>\n",
              "      <td>1.074218e+06</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2015.000000</td>\n",
              "      <td>2015.000000</td>\n",
              "      <td>122072.000000</td>\n",
              "      <td>53.007600</td>\n",
              "      <td>-113.505000</td>\n",
              "      <td>6110.000000</td>\n",
              "      <td>560617.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>7.700000e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46559672-ae72-424d-8fa7-0f7e42a75fb5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46559672-ae72-424d-8fa7-0f7e42a75fb5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46559672-ae72-424d-8fa7-0f7e42a75fb5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E687V5r95qAO",
        "outputId": "ea6a2797-98d6-44ae-9235-58def27a4746"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                                       0\n",
              "Date                                     0\n",
              "number of bedrooms                       0\n",
              "number of bathrooms                      0\n",
              "living area                              0\n",
              "lot area                                 0\n",
              "number of floors                         0\n",
              "waterfront present                       0\n",
              "number of views                          0\n",
              "condition of the house                   0\n",
              "grade of the house                       0\n",
              "Area of the house(excluding basement)    0\n",
              "Area of the basement                     0\n",
              "Built Year                               0\n",
              "Renovation Year                          0\n",
              "Postal Code                              0\n",
              "Lattitude                                0\n",
              "Longitude                                0\n",
              "living_area_renov                        0\n",
              "lot_area_renov                           0\n",
              "Number of schools nearby                 0\n",
              "Distance from the airport                0\n",
              "Price                                    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw8gFI0F604w"
      },
      "source": [
        "## SPLITTING THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xpIss1Ol0Js-"
      },
      "outputs": [],
      "source": [
        "x=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=125)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "s8B-v9Mk1YEY"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDVvU18H65t-"
      },
      "source": [
        "# BUILDING ANN MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4MQgIdp6-py"
      },
      "source": [
        "## Iniatializing ann model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ykT1tkji1Lfg"
      },
      "outputs": [],
      "source": [
        "ann = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3uqDL7v7Gyz"
      },
      "source": [
        "## Adding the input layer and first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mRlDKK1F1gGX"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=64, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5LdfS_T7Sqx"
      },
      "source": [
        "## Adding second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ShdpOirC1rsA"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59r6S2Yw7a_9"
      },
      "source": [
        "## Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "x6qp90fs1uzr"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fAzn3Oa7ivv"
      },
      "source": [
        "# TRAINING THE ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seHcLtiQ7mPl"
      },
      "source": [
        "## Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LEH8p-xG1xCz"
      },
      "outputs": [],
      "source": [
        "ann.compile(optimizer = 'adam',loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARMSRvu_70bs"
      },
      "source": [
        "## Training the model on the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgHjmOpP13Ev",
        "outputId": "2553e9e6-c508-4f29-9b69-ff7096cbd028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 6174978560.0000 - val_loss: 6348682752.0000\n",
            "Epoch 2/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 6146477056.0000 - val_loss: 6246520832.0000\n",
            "Epoch 3/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6157549056.0000 - val_loss: 6290084864.0000\n",
            "Epoch 4/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6117177856.0000 - val_loss: 6227431936.0000\n",
            "Epoch 5/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6127389184.0000 - val_loss: 6306566144.0000\n",
            "Epoch 6/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6122783232.0000 - val_loss: 6373130240.0000\n",
            "Epoch 7/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6107541504.0000 - val_loss: 6261991936.0000\n",
            "Epoch 8/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6095089664.0000 - val_loss: 6229002752.0000\n",
            "Epoch 9/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6088400384.0000 - val_loss: 6234457600.0000\n",
            "Epoch 10/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6090900992.0000 - val_loss: 6333079040.0000\n",
            "Epoch 11/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6061069824.0000 - val_loss: 6286853632.0000\n",
            "Epoch 12/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6055627776.0000 - val_loss: 6255702016.0000\n",
            "Epoch 13/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6048322560.0000 - val_loss: 6266262016.0000\n",
            "Epoch 14/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6027622912.0000 - val_loss: 6335031296.0000\n",
            "Epoch 15/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 6022068224.0000 - val_loss: 6290502656.0000\n",
            "Epoch 16/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 5995008512.0000 - val_loss: 6158895104.0000\n",
            "Epoch 17/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 6006108160.0000 - val_loss: 6178533888.0000\n",
            "Epoch 18/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5994379264.0000 - val_loss: 6202081280.0000\n",
            "Epoch 19/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5966643200.0000 - val_loss: 6182744576.0000\n",
            "Epoch 20/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5968942592.0000 - val_loss: 6123201024.0000\n",
            "Epoch 21/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5966912512.0000 - val_loss: 6157619200.0000\n",
            "Epoch 22/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5956821504.0000 - val_loss: 6175188992.0000\n",
            "Epoch 23/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5944794624.0000 - val_loss: 6171118592.0000\n",
            "Epoch 24/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5926643200.0000 - val_loss: 6125180928.0000\n",
            "Epoch 25/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5916291072.0000 - val_loss: 6194427392.0000\n",
            "Epoch 26/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5895000064.0000 - val_loss: 6116700160.0000\n",
            "Epoch 27/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5899151360.0000 - val_loss: 6181707776.0000\n",
            "Epoch 28/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5887514112.0000 - val_loss: 6247956480.0000\n",
            "Epoch 29/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5874337280.0000 - val_loss: 6189900288.0000\n",
            "Epoch 30/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5857182208.0000 - val_loss: 6116768256.0000\n",
            "Epoch 31/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5855234560.0000 - val_loss: 6072947200.0000\n",
            "Epoch 32/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5844143104.0000 - val_loss: 6167754752.0000\n",
            "Epoch 33/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5840544768.0000 - val_loss: 6240592896.0000\n",
            "Epoch 34/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5813682688.0000 - val_loss: 6096271872.0000\n",
            "Epoch 35/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5814463488.0000 - val_loss: 6125452288.0000\n",
            "Epoch 36/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5815566336.0000 - val_loss: 6157626880.0000\n",
            "Epoch 37/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5793843712.0000 - val_loss: 6095767552.0000\n",
            "Epoch 38/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5794157056.0000 - val_loss: 6092219392.0000\n",
            "Epoch 39/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5782161920.0000 - val_loss: 6089477632.0000\n",
            "Epoch 40/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5742356992.0000 - val_loss: 6013300224.0000\n",
            "Epoch 41/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5758237696.0000 - val_loss: 6065687040.0000\n",
            "Epoch 42/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5743282688.0000 - val_loss: 6110983168.0000\n",
            "Epoch 43/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 5736336384.0000 - val_loss: 6113174528.0000\n",
            "Epoch 44/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 5717426688.0000 - val_loss: 6093627392.0000\n",
            "Epoch 45/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5701380608.0000 - val_loss: 5996601856.0000\n",
            "Epoch 46/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5711917056.0000 - val_loss: 6062772224.0000\n",
            "Epoch 47/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5684118016.0000 - val_loss: 5996668416.0000\n",
            "Epoch 48/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5679855616.0000 - val_loss: 6086484992.0000\n",
            "Epoch 49/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5678743552.0000 - val_loss: 6059759616.0000\n",
            "Epoch 50/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5657415168.0000 - val_loss: 6120241664.0000\n",
            "Epoch 51/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5645265408.0000 - val_loss: 6096067072.0000\n",
            "Epoch 52/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5638944256.0000 - val_loss: 6020937728.0000\n",
            "Epoch 53/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5623901696.0000 - val_loss: 5984566272.0000\n",
            "Epoch 54/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5629503488.0000 - val_loss: 6023485952.0000\n",
            "Epoch 55/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5613835776.0000 - val_loss: 6094226944.0000\n",
            "Epoch 56/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5607915520.0000 - val_loss: 6092335104.0000\n",
            "Epoch 57/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5590188032.0000 - val_loss: 5965015552.0000\n",
            "Epoch 58/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5575672832.0000 - val_loss: 5973450752.0000\n",
            "Epoch 59/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5586060800.0000 - val_loss: 6073601024.0000\n",
            "Epoch 60/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5572302336.0000 - val_loss: 5976760320.0000\n",
            "Epoch 61/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5557426688.0000 - val_loss: 5994537472.0000\n",
            "Epoch 62/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5551429120.0000 - val_loss: 6031694848.0000\n",
            "Epoch 63/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5527106560.0000 - val_loss: 5940784640.0000\n",
            "Epoch 64/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5518183424.0000 - val_loss: 6016480768.0000\n",
            "Epoch 65/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5524490752.0000 - val_loss: 5894966784.0000\n",
            "Epoch 66/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5512752640.0000 - val_loss: 6011629568.0000\n",
            "Epoch 67/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5488653312.0000 - val_loss: 5871212032.0000\n",
            "Epoch 68/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5477962752.0000 - val_loss: 5938110976.0000\n",
            "Epoch 69/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5476173824.0000 - val_loss: 5953776640.0000\n",
            "Epoch 70/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5478434304.0000 - val_loss: 5910247424.0000\n",
            "Epoch 71/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5465958912.0000 - val_loss: 6036056064.0000\n",
            "Epoch 72/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 5442753024.0000 - val_loss: 5854038016.0000\n",
            "Epoch 73/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5454357504.0000 - val_loss: 5857871872.0000\n",
            "Epoch 74/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5408977920.0000 - val_loss: 6146810368.0000\n",
            "Epoch 75/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5444549632.0000 - val_loss: 5878694400.0000\n",
            "Epoch 76/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5420526592.0000 - val_loss: 6038998528.0000\n",
            "Epoch 77/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5405752320.0000 - val_loss: 5838642688.0000\n",
            "Epoch 78/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5394508288.0000 - val_loss: 5968951296.0000\n",
            "Epoch 79/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5385649664.0000 - val_loss: 5877862912.0000\n",
            "Epoch 80/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5373331456.0000 - val_loss: 5996507648.0000\n",
            "Epoch 81/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5360996352.0000 - val_loss: 5854474240.0000\n",
            "Epoch 82/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5366523904.0000 - val_loss: 5809226752.0000\n",
            "Epoch 83/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5357229056.0000 - val_loss: 5855041536.0000\n",
            "Epoch 84/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5346622464.0000 - val_loss: 5926158848.0000\n",
            "Epoch 85/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5343147520.0000 - val_loss: 5881533952.0000\n",
            "Epoch 86/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 5319527936.0000 - val_loss: 5875206144.0000\n",
            "Epoch 87/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5318209536.0000 - val_loss: 5832353792.0000\n",
            "Epoch 88/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5316315648.0000 - val_loss: 5814026752.0000\n",
            "Epoch 89/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5293612544.0000 - val_loss: 5803164672.0000\n",
            "Epoch 90/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5267484672.0000 - val_loss: 5985573888.0000\n",
            "Epoch 91/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5303600128.0000 - val_loss: 5755273728.0000\n",
            "Epoch 92/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5270772736.0000 - val_loss: 5864894464.0000\n",
            "Epoch 93/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5257197056.0000 - val_loss: 5715415040.0000\n",
            "Epoch 94/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5273155584.0000 - val_loss: 5719596032.0000\n",
            "Epoch 95/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5255984128.0000 - val_loss: 5742913024.0000\n",
            "Epoch 96/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5246591488.0000 - val_loss: 5747287552.0000\n",
            "Epoch 97/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5236428800.0000 - val_loss: 5810281472.0000\n",
            "Epoch 98/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5226757632.0000 - val_loss: 5806327296.0000\n",
            "Epoch 99/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5224660992.0000 - val_loss: 5851846656.0000\n",
            "Epoch 100/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5197701632.0000 - val_loss: 5729573376.0000\n",
            "Epoch 101/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5207319552.0000 - val_loss: 5715788288.0000\n",
            "Epoch 102/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5184983552.0000 - val_loss: 5916327424.0000\n",
            "Epoch 103/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5192649216.0000 - val_loss: 5850327040.0000\n",
            "Epoch 104/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5172748800.0000 - val_loss: 5798487552.0000\n",
            "Epoch 105/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5158887936.0000 - val_loss: 5827429376.0000\n",
            "Epoch 106/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5157984768.0000 - val_loss: 5867169792.0000\n",
            "Epoch 107/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5147769344.0000 - val_loss: 5752734208.0000\n",
            "Epoch 108/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5139502080.0000 - val_loss: 5858714112.0000\n",
            "Epoch 109/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5129348608.0000 - val_loss: 5700209152.0000\n",
            "Epoch 110/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5115386880.0000 - val_loss: 5744031232.0000\n",
            "Epoch 111/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5115313664.0000 - val_loss: 5677556736.0000\n",
            "Epoch 112/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5111184896.0000 - val_loss: 5770350592.0000\n",
            "Epoch 113/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5090560000.0000 - val_loss: 5698281472.0000\n",
            "Epoch 114/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 5085924864.0000 - val_loss: 5723923456.0000\n",
            "Epoch 115/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 5084604928.0000 - val_loss: 5835907072.0000\n",
            "Epoch 116/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5052122112.0000 - val_loss: 5634562560.0000\n",
            "Epoch 117/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5062703616.0000 - val_loss: 5718842368.0000\n",
            "Epoch 118/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5066072064.0000 - val_loss: 5740911104.0000\n",
            "Epoch 119/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5037841920.0000 - val_loss: 5625796096.0000\n",
            "Epoch 120/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5024927232.0000 - val_loss: 5824681984.0000\n",
            "Epoch 121/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5025119744.0000 - val_loss: 5749638144.0000\n",
            "Epoch 122/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5020303872.0000 - val_loss: 5690289664.0000\n",
            "Epoch 123/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 5027957248.0000 - val_loss: 5719680000.0000\n",
            "Epoch 124/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4993049600.0000 - val_loss: 5598258176.0000\n",
            "Epoch 125/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4997167104.0000 - val_loss: 5699710976.0000\n",
            "Epoch 126/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4982536192.0000 - val_loss: 5637868032.0000\n",
            "Epoch 127/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4977157632.0000 - val_loss: 5619797504.0000\n",
            "Epoch 128/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 4956846592.0000 - val_loss: 5691478528.0000\n",
            "Epoch 129/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 4965689344.0000 - val_loss: 5571492864.0000\n",
            "Epoch 130/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4953691648.0000 - val_loss: 5696898560.0000\n",
            "Epoch 131/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4951621632.0000 - val_loss: 5732231680.0000\n",
            "Epoch 132/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4948087808.0000 - val_loss: 5597071360.0000\n",
            "Epoch 133/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4925936640.0000 - val_loss: 5667242496.0000\n",
            "Epoch 134/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4927138304.0000 - val_loss: 5633756672.0000\n",
            "Epoch 135/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4925509120.0000 - val_loss: 5654891008.0000\n",
            "Epoch 136/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4922110976.0000 - val_loss: 5595261952.0000\n",
            "Epoch 137/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4891662848.0000 - val_loss: 5668552192.0000\n",
            "Epoch 138/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4889874944.0000 - val_loss: 5794225664.0000\n",
            "Epoch 139/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4889344512.0000 - val_loss: 5586866688.0000\n",
            "Epoch 140/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4870946304.0000 - val_loss: 5555565568.0000\n",
            "Epoch 141/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4873065984.0000 - val_loss: 5542329344.0000\n",
            "Epoch 142/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4853206016.0000 - val_loss: 5659950080.0000\n",
            "Epoch 143/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 4837001728.0000 - val_loss: 5567740416.0000\n",
            "Epoch 144/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4818490880.0000 - val_loss: 5771557888.0000\n",
            "Epoch 145/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4829254144.0000 - val_loss: 5588892160.0000\n",
            "Epoch 146/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4819382784.0000 - val_loss: 5706443264.0000\n",
            "Epoch 147/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4818297856.0000 - val_loss: 5547260416.0000\n",
            "Epoch 148/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4808334336.0000 - val_loss: 5592339968.0000\n",
            "Epoch 149/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4794467328.0000 - val_loss: 5644040192.0000\n",
            "Epoch 150/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4787581440.0000 - val_loss: 5525999616.0000\n",
            "Epoch 151/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4799127040.0000 - val_loss: 5508541440.0000\n",
            "Epoch 152/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4763776000.0000 - val_loss: 5504986624.0000\n",
            "Epoch 153/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4769176064.0000 - val_loss: 5489647104.0000\n",
            "Epoch 154/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4754805760.0000 - val_loss: 5546650624.0000\n",
            "Epoch 155/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4740909568.0000 - val_loss: 5473498112.0000\n",
            "Epoch 156/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4743394304.0000 - val_loss: 5485701120.0000\n",
            "Epoch 157/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4733802496.0000 - val_loss: 5565982720.0000\n",
            "Epoch 158/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 4712160768.0000 - val_loss: 5447140864.0000\n",
            "Epoch 159/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4711775232.0000 - val_loss: 5528573952.0000\n",
            "Epoch 160/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4717787136.0000 - val_loss: 5535800320.0000\n",
            "Epoch 161/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4710606848.0000 - val_loss: 5519693312.0000\n",
            "Epoch 162/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4683251200.0000 - val_loss: 5473131520.0000\n",
            "Epoch 163/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4677279744.0000 - val_loss: 5643040256.0000\n",
            "Epoch 164/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4681933824.0000 - val_loss: 5539345408.0000\n",
            "Epoch 165/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4663505920.0000 - val_loss: 5569646080.0000\n",
            "Epoch 166/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4662879232.0000 - val_loss: 5618875392.0000\n",
            "Epoch 167/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4654854144.0000 - val_loss: 5554209280.0000\n",
            "Epoch 168/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4632758272.0000 - val_loss: 5614087168.0000\n",
            "Epoch 169/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4634555392.0000 - val_loss: 5453614592.0000\n",
            "Epoch 170/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4635585024.0000 - val_loss: 5420959232.0000\n",
            "Epoch 171/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4623786496.0000 - val_loss: 5506895360.0000\n",
            "Epoch 172/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4613707776.0000 - val_loss: 5526580224.0000\n",
            "Epoch 173/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4599470080.0000 - val_loss: 5503966720.0000\n",
            "Epoch 174/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4603595264.0000 - val_loss: 5588696576.0000\n",
            "Epoch 175/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4593771520.0000 - val_loss: 5477877248.0000\n",
            "Epoch 176/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4594454016.0000 - val_loss: 5541868544.0000\n",
            "Epoch 177/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4551662080.0000 - val_loss: 5645028864.0000\n",
            "Epoch 178/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4557307392.0000 - val_loss: 5504098304.0000\n",
            "Epoch 179/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4559767040.0000 - val_loss: 5543041536.0000\n",
            "Epoch 180/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4538932224.0000 - val_loss: 5477686272.0000\n",
            "Epoch 181/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4537961984.0000 - val_loss: 5522956288.0000\n",
            "Epoch 182/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4536878080.0000 - val_loss: 5474881536.0000\n",
            "Epoch 183/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4530388480.0000 - val_loss: 5516695552.0000\n",
            "Epoch 184/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4511792128.0000 - val_loss: 5647975424.0000\n",
            "Epoch 185/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4508080640.0000 - val_loss: 5508692480.0000\n",
            "Epoch 186/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4490746368.0000 - val_loss: 5513104384.0000\n",
            "Epoch 187/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4493749760.0000 - val_loss: 5508717568.0000\n",
            "Epoch 188/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4492303360.0000 - val_loss: 5492918784.0000\n",
            "Epoch 189/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4483666944.0000 - val_loss: 5506779136.0000\n",
            "Epoch 190/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4466780672.0000 - val_loss: 5508070400.0000\n",
            "Epoch 191/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4462660096.0000 - val_loss: 5522881024.0000\n",
            "Epoch 192/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4448050688.0000 - val_loss: 5451291136.0000\n",
            "Epoch 193/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4431933952.0000 - val_loss: 5591950336.0000\n",
            "Epoch 194/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4436127232.0000 - val_loss: 5553958400.0000\n",
            "Epoch 195/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4415111680.0000 - val_loss: 5456003584.0000\n",
            "Epoch 196/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4424192000.0000 - val_loss: 5407360000.0000\n",
            "Epoch 197/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4409802752.0000 - val_loss: 5502677504.0000\n",
            "Epoch 198/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4395595264.0000 - val_loss: 5329740288.0000\n",
            "Epoch 199/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4401854976.0000 - val_loss: 5466006528.0000\n",
            "Epoch 200/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4387042816.0000 - val_loss: 5548745216.0000\n",
            "Epoch 201/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4368738304.0000 - val_loss: 5393812992.0000\n",
            "Epoch 202/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 4366495232.0000 - val_loss: 5383655424.0000\n",
            "Epoch 203/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4338013696.0000 - val_loss: 5273150976.0000\n",
            "Epoch 204/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4363712512.0000 - val_loss: 5410105856.0000\n",
            "Epoch 205/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4342893056.0000 - val_loss: 5444364288.0000\n",
            "Epoch 206/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4327675904.0000 - val_loss: 5473655296.0000\n",
            "Epoch 207/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4322272768.0000 - val_loss: 5385104896.0000\n",
            "Epoch 208/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4319962624.0000 - val_loss: 5431033856.0000\n",
            "Epoch 209/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4302264320.0000 - val_loss: 5473696256.0000\n",
            "Epoch 210/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4301105152.0000 - val_loss: 5365697536.0000\n",
            "Epoch 211/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4294907648.0000 - val_loss: 5447948288.0000\n",
            "Epoch 212/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4277915136.0000 - val_loss: 5315443712.0000\n",
            "Epoch 213/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4292092672.0000 - val_loss: 5373233152.0000\n",
            "Epoch 214/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4284979200.0000 - val_loss: 5346386944.0000\n",
            "Epoch 215/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 4271688192.0000 - val_loss: 5503337984.0000\n",
            "Epoch 216/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4249943040.0000 - val_loss: 5445777920.0000\n",
            "Epoch 217/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4243126016.0000 - val_loss: 5263859712.0000\n",
            "Epoch 218/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4259393792.0000 - val_loss: 5375711232.0000\n",
            "Epoch 219/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4215302144.0000 - val_loss: 5288516608.0000\n",
            "Epoch 220/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4225429248.0000 - val_loss: 5380700160.0000\n",
            "Epoch 221/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4216985088.0000 - val_loss: 5348739072.0000\n",
            "Epoch 222/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4209114880.0000 - val_loss: 5476353536.0000\n",
            "Epoch 223/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4219186176.0000 - val_loss: 5378484224.0000\n",
            "Epoch 224/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4199318016.0000 - val_loss: 5293432320.0000\n",
            "Epoch 225/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4191313152.0000 - val_loss: 5297065472.0000\n",
            "Epoch 226/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4188665856.0000 - val_loss: 5357321216.0000\n",
            "Epoch 227/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4179406592.0000 - val_loss: 5494858240.0000\n",
            "Epoch 228/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4174962432.0000 - val_loss: 5255415296.0000\n",
            "Epoch 229/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4156237056.0000 - val_loss: 5368502272.0000\n",
            "Epoch 230/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4147979776.0000 - val_loss: 5369536512.0000\n",
            "Epoch 231/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4130141440.0000 - val_loss: 5254021120.0000\n",
            "Epoch 232/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4134062592.0000 - val_loss: 5324203008.0000\n",
            "Epoch 233/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4125041408.0000 - val_loss: 5360038400.0000\n",
            "Epoch 234/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4112701184.0000 - val_loss: 5413348864.0000\n",
            "Epoch 235/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4107598592.0000 - val_loss: 5407627776.0000\n",
            "Epoch 236/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4098354176.0000 - val_loss: 5435425792.0000\n",
            "Epoch 237/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4090529024.0000 - val_loss: 5275153408.0000\n",
            "Epoch 238/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4086585088.0000 - val_loss: 5407591936.0000\n",
            "Epoch 239/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4054359552.0000 - val_loss: 5470540288.0000\n",
            "Epoch 240/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4062274560.0000 - val_loss: 5415176704.0000\n",
            "Epoch 241/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4049991680.0000 - val_loss: 5217086464.0000\n",
            "Epoch 242/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4049715968.0000 - val_loss: 5338304512.0000\n",
            "Epoch 243/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4050822912.0000 - val_loss: 5300030464.0000\n",
            "Epoch 244/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 4025123328.0000 - val_loss: 5372324352.0000\n",
            "Epoch 245/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 4005586432.0000 - val_loss: 5142982144.0000\n",
            "Epoch 246/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4018222848.0000 - val_loss: 5154041344.0000\n",
            "Epoch 247/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4008405504.0000 - val_loss: 5231992320.0000\n",
            "Epoch 248/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3988011264.0000 - val_loss: 5331344384.0000\n",
            "Epoch 249/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3988737536.0000 - val_loss: 5195152384.0000\n",
            "Epoch 250/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 4005912576.0000 - val_loss: 5349065216.0000\n",
            "Epoch 251/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3975437824.0000 - val_loss: 5320850944.0000\n",
            "Epoch 252/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3979996416.0000 - val_loss: 5192431616.0000\n",
            "Epoch 253/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3968877056.0000 - val_loss: 5301542912.0000\n",
            "Epoch 254/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3947122688.0000 - val_loss: 5167074304.0000\n",
            "Epoch 255/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3943321344.0000 - val_loss: 5251796992.0000\n",
            "Epoch 256/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3933414144.0000 - val_loss: 5155485184.0000\n",
            "Epoch 257/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3928638208.0000 - val_loss: 5320280576.0000\n",
            "Epoch 258/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3939887360.0000 - val_loss: 5249531392.0000\n",
            "Epoch 259/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3916288512.0000 - val_loss: 5185285120.0000\n",
            "Epoch 260/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3915562752.0000 - val_loss: 5361956352.0000\n",
            "Epoch 261/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3895947520.0000 - val_loss: 5433027072.0000\n",
            "Epoch 262/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3892319488.0000 - val_loss: 5125833728.0000\n",
            "Epoch 263/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3890377984.0000 - val_loss: 5236962816.0000\n",
            "Epoch 264/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3883041792.0000 - val_loss: 5144733184.0000\n",
            "Epoch 265/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3870640128.0000 - val_loss: 5342527488.0000\n",
            "Epoch 266/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3854088448.0000 - val_loss: 5454661120.0000\n",
            "Epoch 267/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3869563648.0000 - val_loss: 5308454912.0000\n",
            "Epoch 268/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3846361088.0000 - val_loss: 5180737536.0000\n",
            "Epoch 269/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3846783488.0000 - val_loss: 5192976384.0000\n",
            "Epoch 270/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3844366080.0000 - val_loss: 5201318912.0000\n",
            "Epoch 271/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3819785984.0000 - val_loss: 5259690496.0000\n",
            "Epoch 272/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3810976768.0000 - val_loss: 5209792000.0000\n",
            "Epoch 273/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3800265728.0000 - val_loss: 5057564672.0000\n",
            "Epoch 274/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 3819083520.0000 - val_loss: 5138163200.0000\n",
            "Epoch 275/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3801187328.0000 - val_loss: 5302766592.0000\n",
            "Epoch 276/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3794530560.0000 - val_loss: 5166303232.0000\n",
            "Epoch 277/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3775191808.0000 - val_loss: 5136814592.0000\n",
            "Epoch 278/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3769852416.0000 - val_loss: 5213897728.0000\n",
            "Epoch 279/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3764992512.0000 - val_loss: 5229328384.0000\n",
            "Epoch 280/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3763362304.0000 - val_loss: 5244057088.0000\n",
            "Epoch 281/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3761457664.0000 - val_loss: 5254312960.0000\n",
            "Epoch 282/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3756984576.0000 - val_loss: 5230138368.0000\n",
            "Epoch 283/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3733083648.0000 - val_loss: 5085806592.0000\n",
            "Epoch 284/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3740032512.0000 - val_loss: 5137414144.0000\n",
            "Epoch 285/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3726042368.0000 - val_loss: 5138375680.0000\n",
            "Epoch 286/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3728356864.0000 - val_loss: 5169121280.0000\n",
            "Epoch 287/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3716623360.0000 - val_loss: 5194634752.0000\n",
            "Epoch 288/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3713910528.0000 - val_loss: 5177885696.0000\n",
            "Epoch 289/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3714423296.0000 - val_loss: 5225239040.0000\n",
            "Epoch 290/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 3698000896.0000 - val_loss: 5191412224.0000\n",
            "Epoch 291/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3682237440.0000 - val_loss: 5310609408.0000\n",
            "Epoch 292/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3692016128.0000 - val_loss: 5094408704.0000\n",
            "Epoch 293/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3677273088.0000 - val_loss: 5107458048.0000\n",
            "Epoch 294/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3674257920.0000 - val_loss: 5301511168.0000\n",
            "Epoch 295/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3675931648.0000 - val_loss: 5325135872.0000\n",
            "Epoch 296/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3664236288.0000 - val_loss: 5120229888.0000\n",
            "Epoch 297/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3667525120.0000 - val_loss: 5196176384.0000\n",
            "Epoch 298/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3642756352.0000 - val_loss: 4995456000.0000\n",
            "Epoch 299/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3654236160.0000 - val_loss: 5145622528.0000\n",
            "Epoch 300/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3631691776.0000 - val_loss: 5162057728.0000\n",
            "Epoch 301/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3624178176.0000 - val_loss: 5197382144.0000\n",
            "Epoch 302/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3637157888.0000 - val_loss: 5009390080.0000\n",
            "Epoch 303/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3598302464.0000 - val_loss: 5327082496.0000\n",
            "Epoch 304/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3596691712.0000 - val_loss: 5016761856.0000\n",
            "Epoch 305/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 3599197696.0000 - val_loss: 4999627776.0000\n",
            "Epoch 306/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3606008320.0000 - val_loss: 5009127936.0000\n",
            "Epoch 307/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3580699136.0000 - val_loss: 5278524928.0000\n",
            "Epoch 308/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3588685056.0000 - val_loss: 5083495424.0000\n",
            "Epoch 309/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3567507200.0000 - val_loss: 5081463808.0000\n",
            "Epoch 310/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3569446656.0000 - val_loss: 5038550016.0000\n",
            "Epoch 311/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3569723392.0000 - val_loss: 5015296000.0000\n",
            "Epoch 312/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3546642944.0000 - val_loss: 5023046144.0000\n",
            "Epoch 313/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3539108608.0000 - val_loss: 5104137728.0000\n",
            "Epoch 314/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3543148288.0000 - val_loss: 4943027200.0000\n",
            "Epoch 315/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3540676352.0000 - val_loss: 5105530368.0000\n",
            "Epoch 316/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3529043456.0000 - val_loss: 5040681472.0000\n",
            "Epoch 317/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3506045184.0000 - val_loss: 5189282816.0000\n",
            "Epoch 318/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 3529161216.0000 - val_loss: 5135586816.0000\n",
            "Epoch 319/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3527762432.0000 - val_loss: 5090740224.0000\n",
            "Epoch 320/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3501513984.0000 - val_loss: 5110369792.0000\n",
            "Epoch 321/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3494579968.0000 - val_loss: 5146525184.0000\n",
            "Epoch 322/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3484007680.0000 - val_loss: 4986260480.0000\n",
            "Epoch 323/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3511250432.0000 - val_loss: 5027475968.0000\n",
            "Epoch 324/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3476737280.0000 - val_loss: 5093969920.0000\n",
            "Epoch 325/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3491659008.0000 - val_loss: 5097719808.0000\n",
            "Epoch 326/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3486911232.0000 - val_loss: 4950756352.0000\n",
            "Epoch 327/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3458177792.0000 - val_loss: 5008028160.0000\n",
            "Epoch 328/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3458522112.0000 - val_loss: 5002306560.0000\n",
            "Epoch 329/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3447292672.0000 - val_loss: 5145351168.0000\n",
            "Epoch 330/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3436489728.0000 - val_loss: 4909108736.0000\n",
            "Epoch 331/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3427941376.0000 - val_loss: 5109318656.0000\n",
            "Epoch 332/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3418197504.0000 - val_loss: 5059768832.0000\n",
            "Epoch 333/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 3424273152.0000 - val_loss: 5185938944.0000\n",
            "Epoch 334/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3416505088.0000 - val_loss: 4953672192.0000\n",
            "Epoch 335/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3398686976.0000 - val_loss: 5005148160.0000\n",
            "Epoch 336/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3411030272.0000 - val_loss: 5091038208.0000\n",
            "Epoch 337/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3391900160.0000 - val_loss: 5176043520.0000\n",
            "Epoch 338/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3384923904.0000 - val_loss: 4958793216.0000\n",
            "Epoch 339/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3404603904.0000 - val_loss: 4961506304.0000\n",
            "Epoch 340/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3343408128.0000 - val_loss: 5307826688.0000\n",
            "Epoch 341/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3376757248.0000 - val_loss: 5025817600.0000\n",
            "Epoch 342/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3354067968.0000 - val_loss: 4816357888.0000\n",
            "Epoch 343/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3375268608.0000 - val_loss: 4989961728.0000\n",
            "Epoch 344/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3356871424.0000 - val_loss: 4931429888.0000\n",
            "Epoch 345/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3356711936.0000 - val_loss: 4987309568.0000\n",
            "Epoch 346/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3357774080.0000 - val_loss: 5026281472.0000\n",
            "Epoch 347/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 3334416384.0000 - val_loss: 4972900864.0000\n",
            "Epoch 348/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3332087040.0000 - val_loss: 4987797504.0000\n",
            "Epoch 349/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3325005056.0000 - val_loss: 5035585536.0000\n",
            "Epoch 350/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3316557056.0000 - val_loss: 5078825472.0000\n",
            "Epoch 351/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3321436160.0000 - val_loss: 4913328640.0000\n",
            "Epoch 352/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3337744640.0000 - val_loss: 4924850688.0000\n",
            "Epoch 353/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3298732288.0000 - val_loss: 5031567360.0000\n",
            "Epoch 354/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3281791232.0000 - val_loss: 5112631808.0000\n",
            "Epoch 355/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3271908608.0000 - val_loss: 4823789056.0000\n",
            "Epoch 356/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3283691008.0000 - val_loss: 4898265600.0000\n",
            "Epoch 357/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3287094016.0000 - val_loss: 4816171008.0000\n",
            "Epoch 358/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3260165120.0000 - val_loss: 5110137856.0000\n",
            "Epoch 359/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3265985280.0000 - val_loss: 4862759424.0000\n",
            "Epoch 360/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3260245760.0000 - val_loss: 4914094592.0000\n",
            "Epoch 361/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 3258836736.0000 - val_loss: 4953464832.0000\n",
            "Epoch 362/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3255625984.0000 - val_loss: 4869579264.0000\n",
            "Epoch 363/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3243826176.0000 - val_loss: 5120225280.0000\n",
            "Epoch 364/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3235295232.0000 - val_loss: 4827106816.0000\n",
            "Epoch 365/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3218720256.0000 - val_loss: 4994897408.0000\n",
            "Epoch 366/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3229260800.0000 - val_loss: 4874578944.0000\n",
            "Epoch 367/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3214455296.0000 - val_loss: 4788081152.0000\n",
            "Epoch 368/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3224209152.0000 - val_loss: 4844790272.0000\n",
            "Epoch 369/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3203611904.0000 - val_loss: 4834654208.0000\n",
            "Epoch 370/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3201978112.0000 - val_loss: 4900793344.0000\n",
            "Epoch 371/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3201783040.0000 - val_loss: 4866256896.0000\n",
            "Epoch 372/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3188532480.0000 - val_loss: 4896805888.0000\n",
            "Epoch 373/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3186790400.0000 - val_loss: 4861894656.0000\n",
            "Epoch 374/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3192566784.0000 - val_loss: 4880225280.0000\n",
            "Epoch 375/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3179930368.0000 - val_loss: 4907742720.0000\n",
            "Epoch 376/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3176212736.0000 - val_loss: 4920379904.0000\n",
            "Epoch 377/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3164339456.0000 - val_loss: 4964837888.0000\n",
            "Epoch 378/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3160394496.0000 - val_loss: 4975779328.0000\n",
            "Epoch 379/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3148633088.0000 - val_loss: 4904008704.0000\n",
            "Epoch 380/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3110764544.0000 - val_loss: 4710149120.0000\n",
            "Epoch 381/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3139950336.0000 - val_loss: 4773939712.0000\n",
            "Epoch 382/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3153349120.0000 - val_loss: 4792123904.0000\n",
            "Epoch 383/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3117987328.0000 - val_loss: 5017980416.0000\n",
            "Epoch 384/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3137160192.0000 - val_loss: 4883661312.0000\n",
            "Epoch 385/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3131649280.0000 - val_loss: 4898076160.0000\n",
            "Epoch 386/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3110914048.0000 - val_loss: 4855185920.0000\n",
            "Epoch 387/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3119100928.0000 - val_loss: 4888399872.0000\n",
            "Epoch 388/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3098925312.0000 - val_loss: 4916604416.0000\n",
            "Epoch 389/400\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 3087810304.0000 - val_loss: 4849405952.0000\n",
            "Epoch 390/400\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 3091681024.0000 - val_loss: 4724574208.0000\n",
            "Epoch 391/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3083228416.0000 - val_loss: 4805518848.0000\n",
            "Epoch 392/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3085721856.0000 - val_loss: 4856351232.0000\n",
            "Epoch 393/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3087618048.0000 - val_loss: 4914159616.0000\n",
            "Epoch 394/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3076111104.0000 - val_loss: 4849412608.0000\n",
            "Epoch 395/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3060160768.0000 - val_loss: 4918640640.0000\n",
            "Epoch 396/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3060488448.0000 - val_loss: 4826148352.0000\n",
            "Epoch 397/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3060425472.0000 - val_loss: 4975063040.0000\n",
            "Epoch 398/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3044075264.0000 - val_loss: 4859015680.0000\n",
            "Epoch 399/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3035897088.0000 - val_loss: 5099400704.0000\n",
            "Epoch 400/400\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 3044576512.0000 - val_loss: 4942330368.0000\n"
          ]
        }
      ],
      "source": [
        "model = ann.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=400, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF9lvXOB7-V-"
      },
      "source": [
        "# EVALUATING THE MODEL "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOgC2NO23Q0X",
        "outputId": "786d41e5-1f78-4c03-e1c7-202268e6495b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 0s 2ms/step\n",
            "MEAN ABSOLUTE ERROR: 20133.46\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "y_pred = ann.predict(x_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'MEAN ABSOLUTE ERROR: {mae:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQDyJ6DHY-zJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}